{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which machine learning algorithms require scaling?\n",
    "KNN and KMeans:- It uses Euclidean distance hence scaling all numerical features to weigh equal.\n",
    "\n",
    "PCA:- PCA tries to get the features with maximum variance and the variance is high for high magnitude features. This skews the PCA towards high magnitude features.\n",
    "\n",
    "Gradient Descent based Algorithms:- Linear regression, Logistic regression, ANN tries to converge faster with scaled features.\n",
    "\n",
    "Na√Øve Bayes and LDA:- They internally handle the weightage of features so scaling may not have much effect.\n",
    "\n",
    "Tree-Based Algorithms:- DecisionTree, RandomForest, Boosting algorithms do not use distance for their computation. Hence scaling is not required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are different types of features scaling?\n",
    "Standardization:- It replaces values with their z scores\n",
    "Xnew=(Xold-Xmean)/ùûÇ\n",
    "\n",
    "This redistributes the features to their mean=0 and standard deviation=1. Its python implementation is available on the sklearn library.\n",
    "\n",
    "Mean Normalization:- This kind of scaling brings the distribution in the range of -1 to 1 with mean=0.\n",
    "     Xnew=(x-min(x)/max(x)-min(x)\n",
    "\n",
    "Standardization and Mean Normalization is used for algorithms that assume zero centric data like PCA.\n",
    "\n",
    "MinMax Scaler:- This scaling technique brings the values in range 0 to 1.\n",
    "Xnew=(x-min(x)/max(x)-min(x)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent Based Algorithms\n",
    "Machine learning algorithms like linear regression, logistic regression, neural network, etc. that use gradient descent as an optimization technique require data to be scaled. Take a look at the formula for gradient descent below:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "The presence of feature value X in the formula will affect the step size of the gradient descent. The difference in ranges of features will cause different step sizes for each feature. To ensure that the gradient descent moves smoothly towards the minima and that the steps for gradient descent are updated at the same rate for all the features, we scale the data before feeding it to the model.\n",
    "\n",
    "Having features on a similar scale can help the gradient descent converge more quickly towards the minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance-Based Algorithms\n",
    "Distance algorithms like KNN, K-means, and SVM are most affected by the range of features. This is because behind the scenes they are using distances between data points to determine their similarity.\n",
    "\n",
    "herefore, we scale our data before employing a distance based algorithm so that all the features contribute equally to the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree-Based Algorithms\n",
    "Tree-based algorithms, on the other hand, are fairly insensitive to the scale of the features. Think about it, a decision tree is only splitting a node based on a single feature. The decision tree splits a node on a feature that increases the homogeneity of the node. This split on a feature is not influenced by other features.\n",
    "\n",
    "So, there is virtually no effect of the remaining features on the split. This is what makes them invariant to the scale of the features!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Normalization?\n",
    "Normalization is a scaling technique in which values are shifted and rescaled so that they end up ranging between 0 and 1. It is also known as Min-Max scaling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Standardization?\n",
    "\n",
    "Standardization is another scaling technique where the values are centered around the mean with a unit standard deviation. This means that the mean of the attribute becomes zero and the resultant distribution has a unit standard deviation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Big Question ‚Äì Normalize or Standardize?\n",
    "Normalization vs. standardization is an eternal question among machine learning newcomers.\n",
    "\n",
    "Normalization is good to use when you know that the distribution of your data does not follow a Gaussian distribution. This can be useful in algorithms that do not assume any distribution of the data like K-Nearest Neighbors and Neural Networks.\n",
    "\n",
    "Standardization, on the other hand, can be helpful in cases where the data follows a Gaussian distribution. However, this does not have to be necessarily true. Also, unlike normalization, standardization does not have a bounding range. So, even if you have outliers in your data, they will not be affected by standardization.\n",
    "\n",
    "However, at the end of the day, the choice of using normalization or standardization will depend on your problem and the machine learning algorithm you are using. There is no hard and fast rule to tell you when to normalize or standardize your data. You can always start by fitting your model to raw, normalized and standardized data and compare the performance for best results.\n",
    "\n",
    "It is a good practice to fit the scaler on the training data and then use it to transform the testing data. This would avoid any data leakage during the model testing process. Also, the scaling of target values is generally not required.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility',\n",
       "       'Item_Type', 'Item_MRP', 'Outlet_Identifier',\n",
       "       'Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type',\n",
       "       'Outlet_Type', 'Item_Outlet_Sales'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation and Scaling Techniques to Boost Your Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature preprocessing is one of the most crucial steps in building a Machine learning model. Too few features and your model won‚Äôt have much to learn from. Too many features and we might be feeding unnecessary information to the model. Not only this, but the values in each of the features need to be considered as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we need Feature Transformation and Scaling?\n",
    "Oftentimes, we have datasets in which different columns have different units ‚Äì like one column can be in kilograms, while another column can be in centimeters. Furthermore, we can have columns like income which can range from 20,000 to 100,000, and even more; while an age column which can range from 0 to 100(at the most). Thus, Income is about 1,000 times larger than age.\n",
    "\n",
    "But how can we be sure that the model treats both these variables equally? When we feed these features to the model as is, there is every chance that the income will influence the result more due to its larger value. But this doesn‚Äôt necessarily mean it is more important as a predictor. So, to give importance to both Age, and Income, we need feature scaling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Income': [15000, 1800, 120000, 10000],\n",
    "    'Age': [25, 18, 42, 51],\n",
    "    'Department': ['HR','Legal','Marketing','Management']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>25</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>18</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>42</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>51</td>\n",
       "      <td>Management</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Income  Age  Department\n",
       "0   15000   25          HR\n",
       "1    1800   18       Legal\n",
       "2  120000   42   Marketing\n",
       "3   10000   51  Management"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### Before directly applying any feature transformation or scaling technique, we need to remember the categorical column: Department, and first deal with it. This is because we cannot scale non-numeric values.\n",
    "\n",
    "For that, we 1st create a copy of our dataframe and store the numerical feature names in a list, and their values as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = df.copy()\n",
    "col_names = ['Income', 'Age']\n",
    "features = df_scaled[col_names]\n",
    "#We will execute this snippet before using a new scaler every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMax Scaler\n",
    "The MinMax scaler is one of the simplest scalers to understand.  It just scales all the data between 0 and 1. The formula for calculating the scaled value is-\n",
    "\n",
    "x_scaled = (x ‚Äì x_min)/(x_max ‚Äì x_min)\n",
    "Thus, a point to note is that it does so for every feature separately. Though (0, 1) is the default range, we can define our range of max and min values as well. How to implement the MinMax scaler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first import it\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#apply only on the values of the features\n",
    "\n",
    "df_scaled[col_names] = scaler.fit_transform(features.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.111675</td>\n",
       "      <td>0.212121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.069374</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Income       Age\n",
       "0  0.111675  0.212121\n",
       "1  0.000000  0.000000\n",
       "2  1.000000  0.727273\n",
       "3  0.069374  1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled[col_names]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "However, suppose we don‚Äôt want the income or age to have values like 0. Let us take the range to be (5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.558376</td>\n",
       "      <td>6.060606</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.636364</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.346870</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>Management</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Income        Age  Department\n",
       "0   5.558376   6.060606          HR\n",
       "1   5.000000   5.000000       Legal\n",
       "2  10.000000   8.636364   Marketing\n",
       "3   5.346870  10.000000  Management"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(5, 10)) # range is from 5 to 10 here\n",
    "\n",
    "df_scaled[col_names] = scaler.fit_transform(features.values)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The min-max scaler lets you set the range in which you want the variables to be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Scaler\n",
    "Just like the MinMax Scaler, the Standard Scaler is another popular scaler that is very easy to understand and implement.\n",
    "\n",
    "For each feature, the Standard Scaler scales the values such that the mean is 0 and the standard deviation is 1(or the variance).\n",
    "\n",
    "x_scaled = x ‚Äì mean/std_dev\n",
    "However, Standard Scaler assumes that the distribution of the variable is normal. Thus, in case, the variables are not normally distributed, we\n",
    "\n",
    "either choose a different scaler\n",
    "or first, convert the variables to a normal distribution and then apply this scaler\n",
    "Implementing the standard scaler is much similar to implementing a min-max scaler. Just like before, we will first import StandardScaler and then use it to transform our variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.449056</td>\n",
       "      <td>-0.685248</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.722214</td>\n",
       "      <td>-1.218219</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.723796</td>\n",
       "      <td>0.609110</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.552525</td>\n",
       "      <td>1.294358</td>\n",
       "      <td>Management</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Income       Age  Department\n",
       "0 -0.449056 -0.685248          HR\n",
       "1 -0.722214 -1.218219       Legal\n",
       "2  1.723796  0.609110   Marketing\n",
       "3 -0.552525  1.294358  Management"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_scaled[col_names] = scaler.fit_transform(features.values)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.551115e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.154701</td>\n",
       "      <td>1.154701e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.722214</td>\n",
       "      <td>-1.218219e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.594947</td>\n",
       "      <td>-8.184910e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.500791</td>\n",
       "      <td>-3.806935e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.094157</td>\n",
       "      <td>7.804217e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.723796</td>\n",
       "      <td>1.294358e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Income           Age\n",
       "count  4.000000  4.000000e+00\n",
       "mean   0.000000 -5.551115e-17\n",
       "std    1.154701  1.154701e+00\n",
       "min   -0.722214 -1.218219e+00\n",
       "25%   -0.594947 -8.184910e-01\n",
       "50%   -0.500791 -3.806935e-02\n",
       "75%    0.094157  7.804217e-01\n",
       "max    1.723796  1.294358e+00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us check the mean and standard deviation of both the columns by performing a describe() function on df_scaled\n",
    "\n",
    "df_scaled.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#You will notice that the values are not exactly, but very close to 0(same with standard deviation). This occurs due to the numerical precision of floating-point numbers in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxAbsScaler\n",
    "In simplest terms, the MaxAbs scaler takes the absolute maximum value of each column and divides each value in the column by the maximum value.\n",
    "\n",
    "Thus, it first takes the absolute value of each value in the column and then takes the maximum value out of those. This operation scales the data between the range [-1, 1].  To see how it works, we will add another column called ‚ÄòBalance‚Äù which contains negative values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Management</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Income       Age  Department\n",
       "0  0.125000  0.490196          HR\n",
       "1  0.015000  0.352941       Legal\n",
       "2  1.000000  0.823529   Marketing\n",
       "3  0.083333  1.000000  Management"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Balance\"] = [100.0, -263.0, 2000.0, -5.0]\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "df_scaled[col_names] = scaler.fit_transform(features.values)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 51, 2000.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can confirm that the MaxAbs Scaler works as expected by printing the maximum values of each column before we scaled it:\n",
    "df[\"Income\"].max(), df[\"Age\"].max(), df['Balance'].max()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Thus, we can see that\n",
    "\n",
    "each value in the Income column is divided by 12000\n",
    "each value in the Age column is divided by 51\n",
    "each value in the Balance column is divided by 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Scaler\n",
    "If you have noticed in the scalers we used so far, each of them was using values like the mean, maximum and minimum values of the columns. All these values are sensitive to outliers. If there are too many outliers in the data, they will influence the mean and the max value or the min value. Thus, even if we scale this data using the above methods, we cannot guarantee a balanced data with a normal distribution.\n",
    "\n",
    "The Robust Scaler, as the name suggests is not sensitive to outliers. This scaler-\n",
    "\n",
    "removes the median from the data\n",
    "scales the data by the InterQuartile Range(IQR)\n",
    "\n",
    "Are you familiar with the Inter-Quartile Range? It is nothing but the difference between the first and third quartile of the variable. The interquartile range can be defined as-\n",
    "\n",
    "IQR = Q3 ‚Äì Q1\n",
    "\n",
    "Thus, the formula would be:\n",
    "\n",
    "x_scaled = (x ‚Äì Q1)/(Q3 ‚Äì Q1)\n",
    "\n",
    "This is the default range, though we can define our own range if we want to. Now let us see how can we implement the Robust Scaler in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.075075</td>\n",
       "      <td>-0.404762</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.321321</td>\n",
       "      <td>-0.738095</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.228228</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.075075</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>Management</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Income       Age  Department\n",
       "0  0.075075 -0.404762          HR\n",
       "1 -0.321321 -0.738095       Legal\n",
       "2  3.228228  0.404762   Marketing\n",
       "3 -0.075075  0.833333  Management"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "df_scaled[col_names] = scaler.fit_transform(features.values)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile Transformer Scaler\n",
    "One of the most interesting feature transformation techniques,the Quantile Transformer Scaler converts the variable distribution to a normal distribution and scales it accordingly. Since it makes the variable normally distributed, it also deals with the outliers. Here are a few important points regarding the Quantile Transformer Scaler:\n",
    "\n",
    "1. It computes the cumulative distribution function of the variable\n",
    "\n",
    "2. It uses this cdf to map the values to a normal distribution\n",
    "\n",
    "3. Maps the obtained values to the desired output distribution using the associated quantile function\n",
    "\n",
    "### A note to keep in mind though: Since this scaler changes the very distribution of the variables, linear relationships among variables may be destroyed by using this scaler. Thus, it is best to use this for non-linear data. Here is the code for using the Quantile Transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ujwal\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2367: UserWarning: n_quantiles (1000) is greater than the total number of samples (4). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\"n_quantiles (%s) is greater than the total number \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Management</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Income       Age  Department\n",
       "0  0.666667  0.333333          HR\n",
       "1  0.000000  0.000000       Legal\n",
       "2  1.000000  0.666667   Marketing\n",
       "3  0.333333  1.000000  Management"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "scaler = QuantileTransformer()\n",
    "\n",
    "df_scaled[col_names] = scaler.fit_transform(features.values)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The effects of both the RobustScaler and the QuantileTransformer can be seen on a larger dataset instead of one with 4 rows. Thus,take up a larger dataset and try these Scalers on their columns to fully understand the changes to the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Transform\n",
    "The Log Transform is one of the most popular Transformation techniques out there. It is primarily used to convert a skewed distribution to a normal distribution/less-skewed distribution. In this transform, we take the log of the values in a column and use these values as the column instead.\n",
    "\n",
    "Why does it work? It is because the log function is equipped to deal with large numbers. Here is an example-\n",
    "\n",
    "log(10) = 1\n",
    "\n",
    "log(100) = 2, and\n",
    "\n",
    "log(10000) = 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_income'] = np.log(df['Income'])\n",
    "# We created a new column to store the log values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "      <th>Balance</th>\n",
       "      <th>log_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>25</td>\n",
       "      <td>HR</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.615805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>18</td>\n",
       "      <td>Legal</td>\n",
       "      <td>-263.0</td>\n",
       "      <td>7.495542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>42</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>11.695247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>51</td>\n",
       "      <td>Management</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>9.210340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Income  Age  Department  Balance  log_income\n",
       "0   15000   25          HR    100.0    9.615805\n",
       "1    1800   18       Legal   -263.0    7.495542\n",
       "2  120000   42   Marketing   2000.0   11.695247\n",
       "3   10000   51  Management     -5.0    9.210340"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Wow! While our Income column had extreme values ranging from 1800 to 1,20,000 ‚Äì the log values are now ranging from approximately 7.5 to 11.7! \n",
    " \n",
    "## Thus, the log operation had a dual role:\n",
    "\n",
    "Reducing the impact of too-low values\n",
    "\n",
    "Reducing the impact of too-high values.\n",
    "\n",
    "### A small caveat though ‚Äì if our data has negative values or values ranging from 0 to 1, we cannot apply log transform directly ‚Äì since the log of negative numbers and numbers between 0 and 1 is undefined, we would get error or NaN values in our data. In such cases, we can add a number to these values to make them all greater than 1. Then, we can apply the log transform.\n",
    "\n",
    "Let us plot a histogram of the above, using 5 bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e2b3d6fa60>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['log_income'].plot.hist(bins = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Transformer Scaler\n",
    "\n",
    "Often use this feature transformation technique when building a linear model. To be more specific, when dealing with heteroskedasticity. Like some other scalers above, the Power Transformer also changes the distribution of the variable, as in, it makes it more Gaussian(normal). We are familiar with similar power transforms such as square root, and cube root transforms, and log transforms.\n",
    "\n",
    "However, to use them, we need to first study the original distribution, and then make a choice. The Power Transformer actually automates this decision making by introducing a parameter called lambda. It decides on a generalized power transform by finding the best value of lambda using either the:\n",
    "\n",
    "1. Box-Cox transform\n",
    "\n",
    "2. The Yeo-Johnson transform\n",
    "\n",
    "Box-Cox works with only positive values, while Yeo-Johnson works with both positive and negative values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125158</td>\n",
       "      <td>-0.597385</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.395497</td>\n",
       "      <td>-1.301984</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.419403</td>\n",
       "      <td>0.681202</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.149064</td>\n",
       "      <td>1.218168</td>\n",
       "      <td>Management</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Income       Age  Department\n",
       "0  0.125158 -0.597385          HR\n",
       "1 -1.395497 -1.301984       Legal\n",
       "2  1.419403  0.681202   Marketing\n",
       "3 -0.149064  1.218168  Management"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "scaler = PowerTransformer(method = 'box-cox')\n",
    "'''\n",
    "parameters:\n",
    "method = 'box-cox' or 'yeo-johnson'\n",
    "'''\n",
    "\n",
    "df_scaled[col_names] = scaler.fit_transform(features.values)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Vector Scaler/Normalizer\n",
    "Normalization is the process of scaling individual samples to have unit norm. The most interesting part is that unlike the other scalers which work on the individual column values, the Normalizer works on the rows! Each row of the dataframe with at least one non-zero component is rescaled independently of other samples so that its norm (l1, l2, or inf) equals one.\n",
    "\n",
    "Just like MinMax Scaler, the Normalizer also converts the values between 0 and 1, and between -1 to 1 when there are negative values in our data.\n",
    "\n",
    "However, there is a difference in the way it does so.\n",
    "\n",
    "If we are using L1 norm, the values in each column are converted so that the sum of their absolute values along the row = 1\n",
    "If we are using L2 norm, the values in each column are first squared and added so that the sum of their absolute values along the row = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>Management</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Income       Age  Department\n",
       "0  0.999999  0.001667          HR\n",
       "1  0.999950  0.010000       Legal\n",
       "2  1.000000  0.000350   Marketing\n",
       "3  0.999987  0.005100  Management"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "scaler = Normalizer(norm = 'l2')\n",
    "# norm = 'l2' is default\n",
    "\n",
    "df_scaled[col_names] = scaler.fit_transform(features.values)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, if you check the first row,\n",
    "\n",
    "(.999999)^2 + (0.001667)^2 = 1.000(approx)\n",
    "\n",
    "Similarly, you can check for all rows, and try out the above with norm = ‚Äòl1‚Äô as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Transformer\n",
    "Consider this situation ‚Äì Suppose you have your own Python function to transform the data. Sklearn also provides the ability to apply this transform to our dataset using what is called a FunctionTransformer.\n",
    "\n",
    "Let us take a simple example. I have a feature transformation technique that involves taking (log to the base 2) of the values. In NumPy, there is a function called log2 which does that for us.\n",
    "\n",
    "Thus, we can now apply the FunctionTransformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.872675</td>\n",
       "      <td>4.643856</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.813781</td>\n",
       "      <td>4.169925</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.872675</td>\n",
       "      <td>5.392317</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.287712</td>\n",
       "      <td>5.672425</td>\n",
       "      <td>Management</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Income       Age  Department\n",
       "0  13.872675  4.643856          HR\n",
       "1  10.813781  4.169925       Legal\n",
       "2  16.872675  5.392317   Marketing\n",
       "3  13.287712  5.672425  Management"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "transformer = FunctionTransformer(np.log2, validate = True)\n",
    "\n",
    "df_scaled[col_names] = transformer.transform(features.values)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
